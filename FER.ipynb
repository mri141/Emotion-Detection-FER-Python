{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq_0iBoE7tbE"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnPlnmdN8gZu"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss6PjYWdB4WT",
        "outputId": "fe3040b8-7b16-4238-86d6-bbd8a5f4ffac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLKZc0v3B7aM",
        "outputId": "f7ad8032-92f4-4aab-f8bd-fb286e907707"
      },
      "source": [
        "base_dir = '/content/drive/My Drive/Deep Learning/Natural Face'\n",
        "\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'test')\n",
        "BATCH_SIZE = 32\n",
        "IMG_RES = (160, 160)\n",
        "\n",
        "training_set = image_dataset_from_directory(train_dir,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_RES)\n",
        "validation_set = image_dataset_from_directory(validation_dir,\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  image_size=IMG_RES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10343 files belonging to 7 classes.\n",
            "Found 4424 files belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3OoKF5XCRWq"
      },
      "source": [
        "num_training_examples = 10343\n",
        "num_classes = 7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRln1tyvC54P"
      },
      "source": [
        "train_image_generator = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "\t  rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "validation_image_generator = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "\t  rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1aUfFY9C8Ea",
        "outputId": "958198c9-b270-45a6-b021-db6adf4d511a"
      },
      "source": [
        "def format_image(image, label):\n",
        "  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
        "  return image, label\n",
        "IMAGE_RES = 224\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                           directory=train_dir,\n",
        "                                                           target_size=(IMAGE_RES,IMAGE_RES), \n",
        "                                                           shuffle=True,\n",
        "                                                           class_mode='sparse')\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              shuffle=False,\n",
        "                                                              target_size=(IMAGE_RES,IMAGE_RES), \n",
        "                                                              class_mode='sparse')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 10343 images belonging to 7 classes.\n",
            "Found 4424 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbdmiwNzC_Kf"
      },
      "source": [
        "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "feature_extractor = hub.KerasLayer(URL,\n",
        "                                   input_shape=(IMAGE_RES, IMAGE_RES, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwJqVVtxDE5l"
      },
      "source": [
        "feature_extractor.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0-6zp5_DHLJ",
        "outputId": "6fcad62a-56b2-4f09-c0fa-7c03a0010640"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  feature_extractor,\n",
        "  layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 7)                 8967      \n",
            "=================================================================\n",
            "Total params: 2,266,951\n",
            "Trainable params: 2,232,839\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4z-xoYmDJKc"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM2BuHpnDPEj",
        "outputId": "ae505375-b028-42c8-e5ca-eff2548443e4"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy',precision_m])\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=int(np.ceil(train_data_gen.n / float(BATCH_SIZE))),\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=int(np.ceil(val_data_gen.n / float(BATCH_SIZE)))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "324/324 [==============================] - 3719s 11s/step - loss: 1.6474 - accuracy: 0.4142 - precision_m: 1.2004 - val_loss: 1.4788 - val_accuracy: 0.5264 - val_precision_m: 1.0036\n",
            "Epoch 2/5\n",
            "324/324 [==============================] - 2387s 7s/step - loss: 1.1970 - accuracy: 0.5945 - precision_m: 1.0522 - val_loss: 1.3508 - val_accuracy: 0.5669 - val_precision_m: 1.0154\n",
            "Epoch 3/5\n",
            "324/324 [==============================] - 2395s 7s/step - loss: 1.0365 - accuracy: 0.6603 - precision_m: 1.0192 - val_loss: 1.2633 - val_accuracy: 0.5961 - val_precision_m: 1.0065\n",
            "Epoch 4/5\n",
            "324/324 [==============================] - 2427s 7s/step - loss: 0.9779 - accuracy: 0.6842 - precision_m: 1.0233 - val_loss: 1.4704 - val_accuracy: 0.5588 - val_precision_m: 1.0032\n",
            "Epoch 5/5\n",
            "324/324 [==============================] - 2342s 7s/step - loss: 0.9201 - accuracy: 0.7069 - precision_m: 1.0083 - val_loss: 1.2423 - val_accuracy: 0.6112 - val_precision_m: 1.0023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaQ3R7CJDcAJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}